import cv2
import numpy as np
import torch
from facenet_pytorch import InceptionResnetV1
from ultralytics import YOLO
import time
from scipy.spatial.distance import cosine

# ‡πÇ‡∏´‡∏•‡∏î YOLOv5 ‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô YOLOv8 ‡πÑ‡∏î‡πâ)
yolo_model_path = "yolov5s.pt"  # ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô .engine ‡∏´‡∏≤‡∏Å‡πÉ‡∏ä‡πâ TensorRT
yolo_model = YOLO(yolo_model_path)

# ‡πÇ‡∏´‡∏•‡∏î FaceNet ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
facenet = InceptionResnetV1(pretrained='vggface2').eval()

# üìù ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤)
known_faces = {
    "Alice": np.random.rand(512),  # ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ embeddings ‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å FaceNet
    "Bob": np.random.rand(512),
    "Charlie": np.random.rand(512)
}
threshold = 0.5  # ‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏ß‡πà‡∏≤ embeddings ‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô (‡∏Ñ‡πà‡∏≤‡πÉ‡∏Å‡∏•‡πâ 0 ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô)

# ‡πÄ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
video_path = r"C:\CPE\PythonOpencvtest\video\5M.mp4"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("‚ùå Error: Could not open video file!")
    exit()

frame_count = 0
start_time = time.time()

while True:
    ret, frame = cap.read()
    if not ret:
        break  # ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏ö

    # YOLO ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
    results = yolo_model(frame)

    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])  # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á
            conf = box.conf[0].item()  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
            cls = int(box.cls[0].item())  # ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà

            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô "person" (YOLO class ID 0)
            if cls == 0 and conf > 0.6:
                face = frame[y1:y2, x1:x2]

                if face.size > 0:
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô RGB ‡πÅ‡∏•‡∏∞‡∏¢‡πà‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î
                    face = cv2.resize(face, (160, 160))
                    face = np.transpose(face, (2, 0, 1)) / 255.0  # Normalize
                    face_tensor = torch.tensor(face, dtype=torch.float32).unsqueeze(0)

                    # ‡πÉ‡∏ä‡πâ FaceNet ‡∏î‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                    with torch.no_grad():
                        face_embedding = facenet(face_tensor).numpy().flatten()

                    # üîç ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                    best_match = "Unknown"
                    best_score = float("inf")

                    for name, known_embedding in known_faces.items():
                        score = cosine(face_embedding, known_embedding)
                        if score < best_score and score < threshold:
                            best_match = name
                            best_score = score

                    # üîπ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á console
                    print(f"üìå Detected: {best_match} (Score: {best_score:.4f})")

                    # üîπ ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(frame, best_match, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
    cv2.imshow("YOLO + FaceNet", frame)
    
    # ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏î 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

    frame_count += 1

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì FPS
end_time = time.time()
fps = frame_count / (end_time - start_time)
print(f"üé• FPS: {fps:.2f}")

cap.release()
cv2.destroyAllWindows()
